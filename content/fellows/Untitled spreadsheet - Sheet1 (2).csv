Please provide a short description of yourself (2-3 sentences).,Please provide a brief description of the work you have done in the fellowship (3-5 sentences) - which could include work you're continuing on with after the fellowship,Please link to any artifacts you created during the fellowship,"Please provide any pertinent links (e.g., institutional affiliation, personal website, LinkedIn profile)."
"Nuño Sempere is a forecaster, programmer and researcher working to detect global risks at Sentinel.",,"1. https://github.com/NunoSempere/eye-of-sauron
2. xrisk.fyi, x.com/xriskfyi
3. tools.sentinel-team.org and tools.sentinel-team.org/twit.html <https://github.com/NunoSempere/tools.sentinel-team.org>
4. https://github.com/NunoSempere/autogenerated-twitter-reports
5. https://github.com/NunoSempere/hdbscan
6. docs.nunosempere.com, e.g., <https://x.com/NunoSempere/status/1965452477538693219>, but also used in the SSC grant round.
7. https://x.com/NunoSempere/status/1965820448123629986
8. https://forecasting.substack.com/

Probably I'm forgetting some small tool or other.","nunosempere.com
https://github.com/NunoSempere
x.com/NunoSempere"
"I'm Herbie Bradley, an AI researcher and writer. I'm a final-year PhD student at the University of Cambridge, and until recently I was at the UK AI Security Institute. I try to find the most impactful problems to solve to help make the future better with AI.","For this fellowship I've focused on the question of how we can create the most impactful content for future AI readers—concretely, around ideas for ""community notes everywhere"" for browsers, and AI-written wikipedia. On the latter, I've worked on building evaluations to measure the current capability of models to fix errors and expand wikipedia articles, as well as prioritization work to figure out in which domains Wikidata and Wikipedia would most benefit from expansion. ",https://docs.google.com/document/d/1KQsiF19t0QSoUQt72_yMTG-28m3kVGE2P8YxVxFeNwg/edit?usp=sharing,https://herbiebradley.com
"Agita Pasaribu is a lawyer and AI-ethics advocate who founded Bullyid App, a tech non-profit supporting victims of online harassment and gender-based violence, reaching 2M+ people through partnerships with Meta, TikTok, UNICEF, and Indonesia’s National Cybercrime Agency. She helped advance Indonesia’s Sexual Violence Law and has contributed to UNESCO’s AI Ethics Recommendation, advised G7/G20 on online safety, and served with the ITU and the Internet Society on global child-safety and digital-ethics initiatives.","Within the fellowship, I am building Evidentry, a coalition infrastructure that connects survivors, online platforms, and regulators to speed up the verification and removal of AI-generated intimate imagery and other non-consensual sexual content. Evidentry has three core layers:
- Multi-detector aggregation: we fuse outputs from leading deepfake-detection models to identify synthetic deception.
- Provenance & evidence (C2PA): we apply C2PA-style provenance and structured evidence capture to generate cryptographically verifiable reports.
- Verification & takedown workflow: we verify claimant/content, then drive a platform-integrated workflow that streamlines case submission, automated evidence review, escalation, and removal confirmation.
This directly addresses today’s regulatory environment. Under frameworks such as the U.S. “Take It Down” provisions, the EU Digital Services Act, and the UK Online Safety Act, platforms are expected to remove non-consensual intimate imagery without undue delay once notified. In practice, the lack of interoperable verification and provenance slows compliance. Evidentry operationalizes these mandates by providing shared, plug-in infrastructure—cutting response times from days to minutes while maintaining evidentiary integrity and auditability.
My research goal is to show how AI-facilitated coordination can embed accountability in real platform operations: multi-detector, provenance confidence scoring to support decisions, and verification and takedown protocols so diverse platforms can act quickly, fairly, and in line with global online-safety laws.",https://evidentry.app,https://www.linkedin.com/in/agitapasaribu/
"My background spans sustainability, entrepreneurship, and the study of how people make decisions. At Amazon, I helped launch the Climate Pledge and led research on sustainable consumption. Today, I’m focused on using AI to strengthen human reasoning and benefit humanity.","During the fellowship, I built an AI system that generates Community Notes on X to help combat misinformation, paired with a dedicated website that hosts long-form fact checks. Each note posted on X links back to the full analysis, allowing readers to explore evidence and reasoning in more depth. This approach combines the accessibility of short-form social content with the rigor of comprehensive fact-checking, and points to a future where AI fact checking complements human reasoning.",https://www.opennotenetwork.com/,https://www.linkedin.com/in/stevecisley/
"Matt is a tech entrepreneur deeply interested in helping AI go well for humanity. He’s experienced in 0 to 1 building, SaaS development, product ideation and iteration, and tinkering with AI.","I built a lot of MVPs to test different ideas related to AI-driven human empowerment / enablement. The projects I built clustered around the themes of sensemaking with unstructured data, communication (digital twin, AI filtering), and matching / coordination. I'm still figuring out / deciding what areas I want to double down on post-fellowship.","https://www.sealednote.com is live and public
All other projects were launched internally but I will write about them on my website - https://mattbrooks.xyz/
A lot of my projects / code is public on github: github.com/MattB543/",https://mattbrooks.xyz/
"Alex's background is in product management of enterprise machine learning infrastructure at Cloudera and AWS. Alex left AWS at the end of 2024 to focus on improving our trajectory through the AGI transition. Recognizing that group communication is integral to the most impactful decisions we make, and the existing pain points of group decision making, Alex identified a critical leverage point for helping humans make wise decisions about the development and distribution of AI.","Alex built several prototypes that use AI to facilitate group sense making and decision making, including the product that would evolve to become Chord. Chord provides AI-orchestrated communication, parallelizing conversations to help groups make better and faster decisions. Alex validated customer demand and the product's impact on group decisions through extensive user testing. Alex founded Sylience to continue building Chord and execute on his broad vision for orchestrated communication.",chord.sylience.com,linkedin.com/in/alexbleakley
I’m a technical builder with a background in climate startups and energy markets. I’m currently focused on creating epistemic and safety evaluations of frontier models.,"My work during the fellowship focused on evaluating both human and model outputs for attributes related to epistemic quality. I used LLMs to assess EA Forum posts along targeted quality dimensions, e.g. Reasoning, Clarity, and Value. I added confidence thresholds and hallucination penalties to frontier evals (HLE, GPQA) to test model calibration and am building a public leaderboard for this. I tested the model ability to identify “after” snapshots from quality-filtered Wikipedia revisions. I measured model sensitivity to epistemically irrelevant contexts—probing for sycophancy and self-protective behavior. I’m planning to build some of these out further in collaboration with other orgs.","Calibrated evals leaderboard preview:
https://calibrated-evals.streamlit.app/

Wikirevisions eval:
https://docs.google.com/document/d/1BWtehm9tYmVy2rFOYY41DjTpII-eIWpPfYPnD-ut45k/edit?tab=t.0

EA forum post quality analysis: https://forum.effectivealtruism.org/posts/7kHX4CEiKJgWfJahY/we-mapped-the-ea-forum-s-intellectual-landscape-read-about#Post_Level_Epistemic_Quality_Analysis",https://www.linkedin.com/in/alejandro-botas-b05b37196/
"Computer scientist and software engineer building innovative systems enhancing human reasoning. Interests span digital democracy, metacognition and tools-for-thought, futures thinking and worldbuilding.","I primarily worked on three projects: Group decision-making software, matchmaking software for the human workforce post-AGI, and a plan for a platform serving as epistemic infrastructure for collective sensemaking around desirable futures.",,https://sofiavanhanen.fi
Paul is a PhD candidate in philosophy and cognitive science. His work focuses on the nature of values and motivation in natural and artificial agents. He is invested in steering the development of AI to improve human flourishing. ,"Paul's work focuses on epistemic and other evals for frontier models. He has worked on clarifying the conditions of being an epistemically virtuous agent, making clear what the targets should be when we operationalize a metric to assess models by. He has also been a part of developing DeliberationBench, a benchmark to assess model influence on users' political views.",TBA,"https://www.pauldfr.com/

https://www.linkedin.com/in/paul-de-font-reaulx-b8920792/"
"Background in policy, government, and geopolitical advisory.","Worked on AI for improving decision-making under uncertainty in policy and government contexts. This took the form of simulation software to assist with scenario generation and wargaming - but ultimately should look like a suite of tools helping make foresight accessible and decision-relevant across a variety of policy contexts. 

Also worked on AI for sensemaking of the expanding literature on AI impacts and future scenarios, and on SF OS, a platform for collaboration between San Francisco government and civic technologists, to accelerate the adoption of beneficial AI into local government,",,https://www.linkedin.com/in/emma-kumleben/
"I have worked on epistemic tools for 3 years. I have built tools for discourse mapping, small group voting, automating forecasts, prediction market question generation. I have been funded by Vitalik Buterin, Jann Tallinn and the FTX Future Fund. ","Rob Gordon and I launched an AI Community Note writer, on X (formerly Twitter). Community Notes is X's highly respected fact checking function. Our bot wrote the world's first ever approved AI community note. Our bots have since written notes that have been viewed 2M times. After launching the bot, we have been working to improve its notes and are currently working on an agent that will call tools to be able to improve its own notes. The bot has gone through about 20 iterations, has a range of filters to remove bad notes and I have built a range of tools to compare bot versions (ELO comparison, iterating on prompts, isolating the worst notes) ","https://nathanpmyoung.substack.com/p/worlds-first-ai-community-note
https://x.com/_jaybaxter_/status/1963244285664620947
https://github.com/Goodheart-Labs/community-notes-writer","https://x.com/NathanpmYoung
https://nathanpmyoung.substack.com/
https://goodheartlabs.com/"
"I am a behavioral scientist interested in building and testing systems that support productive disagreement at scale. I'm concerned about increased political polarization and declining social trust, and am exploring evidence-based approaches to tackle those challenges.","I've co-developed DeliberationBench, a novel AI persuasiveness benchmark that uses the opinion change found in Deliberative Polls as a normative reference point for 'desirable' opinion change, and compares that with the opinion changes induced by conversation with LLMs. We demonstrated this approach in a 4,000-person randomized LLM persuasiveness experiment. 

I also piloted Polis 2.0—a new version of the original collective response platform developed by the computational democracy project—in a large asynchronous dialogue. Over 1,000 quota-sampled Americans voted 90,000+ times on more than 1,000 of their own statements in response to the question: ""what are your highest priority concerns with respect to AI over the next 10 years?""",Links coming soon,"www.linkedin.com/in/maximiliankronerdale

https://www.oii.ox.ac.uk/people/profiles/maximilian-kroner-dale/"
"Nuño Sempere is the Head of Foresight at Sentinel, a team anticipating global risks.","Incubated Sentinel, improving its foresight team, the software that augments it, and our distribution pipeline.",https://github.com/NunoSempere/eye-of-sauron,"xrisk.fyi
nunosempere.com
https://github.com/NunoSempere
https://twitter.com/NunoSempere
https://twitter.com/XriskFYI
xrisk.fyi/fundraiser"
"I'm an organisational strategy researcher who builds tools for groups to coordinate better under uncertainty. I’m currently working on developing low-overhead tools for group subjective decisionmaking about strategy — these tools provide reasoning scaffolds for thinking individually and collectively about argument, value, and evidence. I’m a Fellow of the Singapore Government’s Centre for Strategic Futures and an Honorary Associate Professor at University College London.","I built a self-service webapp that uses LLMs to give users a Socratic mirror and reasoning scaffold for making subjective arguments more rigorous and evidence-backed. The prototype version is designed for college students; it is fully functional and is currently being used by small groups of college students, instructors, and educational technologists. I also have expressions of interest from startups, corporates, and governments for versions tailored for those contexts — I plan to continue this work after the fellowship.","Functional prototype: https://ci1.vercel.app/
Form for getting prototype access: https://forms.gle/Lbgoc3eWSHymdGr7A
Some writing I've done about the project:
1. https://uncertaintymindset.substack.com/p/gbw392025
2. https://vaughntan.org/aiux
3. https://vaughntan.org/thinkingtools","Personal website: https://vaughntan.org/
LinkedIn: https://www.linkedin.com/in/vaughntan/"
"Jamie Joyce is the founding executive director and head ontologist of The Society Library, a nonprofit organization that builds truth-seeking and intelligence tools to improve decision-making, scenario planning, formal inquiry, and public discourse. She also has a longstanding collaboration with the Internet Archive working to preserve previously non-digitized materials in order to improve intelligence and truth-seeking capabilities.  ","Throughout the fellowship, Jamie and her team worked on a new semi-automated information processing pipeline and output format of mass OSINT collection, analyses, and summarization of a complex government event, which culminated in a 600+ intelligence report covering different points of view on the matter. Jamie also has been researching and consulting with experts to learn how the Society Library's structured datasets may be used as benchmarks and evals in truth-seeking capabilities and standards for LLMs.",(just use the video of demo day),"SocietyLibrary.org, JamieJoyce.com, @JustJamieJoyce on Linkedin and X"
"I’m a software engineer focused on democratizing the economy as a key AI safety measure. I was previously the CTO and co-founder of Genesis Therapeutics, an ML-accelerated biotech, and before that head of software at Markforged, developing high-strength 3D printers.","We have built a multi-agent orchestration tool for coordination. Pivotal is an activity log, a shared context, and an agent platform for organizations. It integrates with the software you already use, automates workflows that might otherwise fall through the cracks, and keeps your team on track with a cohesive plan. You can use Pivotal to schedule a Google Meet with a single Slack message, and have it automatically update your GitHub work tracker based on everything mentioned in the meeting. Never forget an action item again!","https://coop.tech, https://github.com/cooperativetech/pivotal",https://www.linkedin.com/in/ben-sklaroff-18b93061
I’m an Econ PhD at MIT primarily working to understand AI progress and its effect on the economy. ,"Created pivotal, an app that helps your team coordinate on scheduling, recording action items, recording organizational context. ",coop.tech ,parkerwhitfill.com
I'm a PhD student at the University of Oxford in computational cognitive neuroscience.,"I worked on benchmarks and evaluations for coordination technology, including the coordination agent Pivotal.","https://coop.tech/, https://github.com/cooperativetech/pivotal",https://www.linkedin.com/in/kaisandbrink/
"Rob Gordon is an indie founder and systems-thinker creating collaborative reasoning tools—like Flowchart Fun and Updraft—to help groups visualize ideas, find consensus, and make better decisions. Blending product design, AI research, and coordination science, he prototypes humane, generative interfaces for collective understanding.","During the fellowship, Rob built Winnow, Prune, and Updraft—three connected experiments in collective sensemaking. Winnow introduced an interactive ratification loop that helps readers and AI co-distill sprawling texts into structured, checkable statements. Prune used a fast Socratic ranking cycle where participants compare and refine ideas in pairs, exploring how deliberation can stay both open-ended and convergent. Updraft became a real-time facilitation tool for ideation and alignment—where groups and AI collaboratively map, cluster, and evolve ideas on a shared 2D canvas. He also collaborated with Nathan Young on applying similar reasoning and evaluation mechanics to Community Notes, experimenting with how AI might enhance public fact-checking and collective epistemic trust.",https://prune.quest/ https://winnow.sh/ https://www.updraft.to/,https://tone-row.com/
"I'm Co-Founder, Board Member, and former CTO of Recursion Pharmaceuticals ($RXRX), where I pioneered machine learning approaches for high-throughput cell imaging to accelerate drug discovery. I shifted his focus in 2017, since then working as a leader, funder, and advisor in AI safety and civilizational robustness, personally and via my GoodForever Foundation. I sit on the boards of MIRI, Topos, Atlas, and Palisade.","I've been exploring how to build better collaboration tools that help groups work together more effectively, especially across different worldviews and disagreements. I'm focused on extending a tool for AI-facilitated group conversations, and prototyping what I call ""social fabric"" - systems that could weave individuals into groups, groups into organizations, and organizations into the broader world through smart intermediaries. I've been doing a lot of rapid UI/UX prototyping and conceptual design work, thinking through ideas like domain-specific trust graphs, pattern languages for collaboration, and ways to create membranes between different communities that let information flow intelligently. I'm also working on making my prototyping workflow more efficient so I can iterate faster and test these ideas with real users. I'm now exploring what kinds of organizations want to be born in this space, that I can help create via research, founding, funding, and more. ",I'll get back to you if I think of things that I want to make public.,
"Niki: I have a background in AI/ML (MSc), and have been doing independent research on using LLMs to augment human thinking for a couple years (within the EA/AI Safety/Lesswrong blogosphere).","I've been exploring topics in scaling bottom-up coordination, from decentralized trust building to matchmaking for collective action. I ended up settling on working primarily on using LLMs to better understand existing internet discourse, and map out the landscape of opinions, with an emphasis on detecting and preventing polarization. I also worked on a semi-automated argument mapper, which I'm also reasonably happy with. ",List of links here: https://lovedoesnotscale.com/flf ,